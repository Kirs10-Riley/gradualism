---
title: "Quantifying U.S. GATT Trade Liberalization"
author: |
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  beamer_presentation:
    theme: "Ilmenau"
    slide_level: 3
header-includes:
  - \setbeamertemplate{navigation symbols}{}
  - \AtBeginDocument{\title[Quantifying U.S. GATT Trade Liberalization  \hspace{2.95in}\insertframenumber/\inserttotalframenumber]{Quantifying U.S. GATT Trade Liberalization}}
  - \AtBeginDocument{\author[Buzard (kbuzard@syr.edu), Jestrab and Xiong]{Kristy Buzard, Syracuse University, kbuzard@syr.edu\\ Ross Jestrab, Syracuse University\\ Zeyuan (Victor) Xiong, Syracuse University}}
  - \usecolortheme{beaver}
  - \AtBeginSection{}
  - \AtBeginSubsection{}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
source("C:/Users/krist/Github/Gradualism/data_cleaning.r", local = knitr::knit_global())
```

# Overview

- Bullet 1
- Bullet 2
- Bullet 3

# Background

- Bullet 1
- Bullet 2
- Bullet 3

# Data

## Data sources

Note that summary statistics throughout the paper for specific tariffs are *not* trade weighted; we are in the process of acquiring the trade data required to both trade weight summary statistics and compute *ad valorem* equivalents.


# Basic Facts

### Item level

```{r echo=F}
same <- function(b,e){
  beg <- shortnames %>% select(ends_with(b))
  end <- shortnames %>% select(ends_with(e))
  name <- substitute(e)
  z <- as.name(paste0("same",name))
  assign(deparse(substitute(z)), shortnames %>%
           filter(((is.na(end[,3]) == T & is.na(beg[,3]) == T) | beg[,3] == end[,3])
                & ((is.na(end[,2]) == T & is.na(beg[,2]) == T) | beg[,2] == end[,2])
                & ((is.na(end[,1]) == T & is.na(beg[,1]) == T) | beg[,1] == end[,1]) )
         , envir=.GlobalEnv)
}  

# below we get the sets of lines for each round compared to SH
same("SH","DB")
same("SH","BG")
same("SH","Ge")
same("SH","An")
same("SH","To")
same("SH","GA")
same("SH","GB")
same("SH","GC")
same("SH","DA")
same("SH","DB")

nr = nrow(shortnames)
num_sameSH <- c(nr,nrow(sameBG),nrow(sameGe),nrow(sameAn),
                nrow(sameTo),nrow(sameGA),nrow(sameGB),
                nrow(sameGC),nrow(sameDA),nrow(sameDB))

same2 <- function(b,e){
  beg <- shortnames %>% select(ends_with(b))
  end <- shortnames %>% select(ends_with(e))
  name1 <- substitute(b)
  name2 <- substitute(e)
  z <- as.name(paste0("same",name1,"_",name2))
  assign(deparse(substitute(z)), shortnames %>%
           filter(((is.na(end[,3]) == T & is.na(beg[,3]) == T) | beg[,3] == end[,3])
                & ((is.na(end[,2]) == T & is.na(beg[,2]) == T) | beg[,2] == end[,2])
                & ((is.na(end[,1]) == T & is.na(beg[,1]) == T) | beg[,1] == end[,1]) )
         , envir=.GlobalEnv)
}  
# all the lines that are exactly the same in Smoot Hawley and Before Geneva
same2("SH","BG")

# below we get the sets of lines for each round compared to the previou round
same2("BG","Ge")
same2("Ge","An")
same2("An","To")
same2("To","GA")
same2("GA","GB")
same2("GB","GC")
same2("GC","DA")
same2("DA","DB")

year <- c(1930,1946,1947,1949,1951,1956,1957,1958,1963,1964)
num_nego <- c(0,nr-nrow(sameSH_BG),nr-nrow(sameBG_Ge),nr-nrow(sameGe_An),nr-nrow(sameAn_To),
            nr-nrow(sameTo_GA),nr-nrow(sameGA_GB),nr-nrow(sameGB_GC),
            nr-nrow(sameGC_DA),nr-nrow(sameDA_DB))
plot1_data <- data.frame(year,num_nego,num_sameSH)
```

```{r ibi, fig.cap = "Tariff Reductions by Number of Items", echo=F}
# Plot
ggplot() + 
  geom_line(data = plot1_data, aes(x=year, y= num_sameSH), color = "blue") +
  annotate("text", label = "No. of items still at Smoot-Hawley level", x = 1948, y = 2700, size = 5, colour = "blue") +
  geom_point(data = plot1_data, aes(x=year, y= num_nego), color = "red") +
  annotate("text", label = "No. of items reduced since previous round", x = 1952, y = 50, size = 5, colour = "red") +
  labs(x="Year", y= "Number of Items") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(1930, 1965, by = 5)) +
  scale_y_continuous(breaks = seq(0, 3000, by = 500))
```

### Complications

- About 15% of items per round have both *ad valorem* and specific components to their tariff in a given round ("compound", following Teti 2020)
<!-- 475 to 505 -->
- Roughly 10% of items are "mixed", i.e. have either an *ad valorem* or specific rate, depending on which is higher
- About 2% of the items are "technical", e.g. defined on proportion of content that meets some criteria
<!-- We do not analyze these categories separately because, insofar as possible, we have integrated them with the basic *ad valorem* and specific types -->

All these are included in the following statistics for compound and *ad valorem*

### Liberalization from 1930 to 1964

```{r echo=FALSE, warning=FALSE}
av_med <- data.frame(ad_valorem[,6:15] %>% sapply(median, na.rm=TRUE))
av_mean <- data.frame(ad_valorem[,6:15] %>% sapply(mean, na.rm=TRUE))
av_count <- data.frame(ad_valorem[,6:15] %>% sapply(function(x) sum(!is.na(x))))
av_min <- data.frame(ad_valorem[,6:15] %>% sapply(min, na.rm=TRUE))
av_max <- data.frame(ad_valorem[,6:15] %>% sapply(max, na.rm=TRUE))
av_25p <- data.frame(ad_valorem[,6:15] %>% sapply(function(x) quantile(x,probs=0.25,na.rm = TRUE)))
av_75p <- data.frame(ad_valorem[,6:15] %>% sapply(function(x) quantile(x,probs=0.75,na.rm = TRUE)))

sp_mean <- data.frame(specific[,6:15] %>% sapply(mean, na.rm=TRUE))
sp_med <- data.frame(specific[,6:15] %>% sapply(median, na.rm=TRUE))
sp_count <- data.frame(specific[,6:15] %>% sapply(function(x) sum(!is.na(x))))
sp_min <- data.frame(specific[,6:15] %>% sapply(min, na.rm=TRUE))
sp_max <- data.frame(specific[,6:15] %>% sapply(max, na.rm=TRUE))
sp_25p <- data.frame(specific[,6:15] %>% sapply(function(x) quantile(x,probs=0.25,na.rm = TRUE)))
sp_75p <- data.frame(specific[,6:15] %>% sapply(function(x) quantile(x,probs=0.75,na.rm = TRUE)))
```

From the Smoot-Hawley tariffs (1930) to the Dillon Round (1964) both *ad valorem* and specific tariffs were cut roughly in half

- mean *ad valorem* tariff binding decreases from `r round(av_mean["Ad_Valorem_SH",],1)`% to `r round(av_mean["Ad_Valorem_Dillon_B",],1)`%
  - medians drop from `r round(av_med["Ad_Valorem_SH",],0)`% to `r round(av_med["Ad_Valorem_Dillon_B",],0)`%
    <!-- Roughly two-thirds of the items in our dataset have an *ad valorem* tariff. -->
- mean specific tariff binding decreases from `r round(sp_mean["Specific_SH",],0)`¢ to `r round(sp_mean["Specific_Dillon_B",],0)`¢
  - medians are much smaller, dropping from `r round(sp_med["Specific_SH",],2)`¢ to `r round(sp_med["Specific_Dillon_B",],2)`¢
  <!-- Specific tariffs are present for roughly half of the items in our data.  -->


## Round-by-Round liberalization

### Tables 1 and 2
(all tables refer to the numbers in data-paper.pdf; source code is in results.rmd)

Task 1

- Level 1: get Table 1 and Table 2 onto this slide and a new one that follows
- Level 2: see if there's some way to combine them into one table (I think this will be hard in terms of just fitting everything in, but worth a try if there's time). If you try it, leave the original two slides and just add a third so I can compare

### Tables 3 and 4
Task 2: get tables 3 and 4 onto this and an additional new slide


## Industry-by-industry liberalization

### Schedule titles
Task 3: get Schedule titles table onto this slide

Task 4:

- Level 1: get tables 6 and 7 onto two new slides
- Level 2: see if you can come up with a way to have clearer titles for the columns that still make sense (this may involve adding another level of header--one that goes across and labels mean vs. median; I think the add_header_above command in "schedules title" table will work)

Task 5: see if you can resize the graph on slide 5 so it fits

# Notable Findings

### Importance of pre-GATT negotiations

### Some lines see tariff increases

### Very few changes between *ad valorem* and specific

# Next steps

## What's next?

- Concordances
  - Smoot-Hawley to TSUS
  - TSUS to HS
  - Smoot-Hawley to 1930's import classification system
- Import volume and value data
  - *Ad valorem* equivalents
  - Trade weighting
  - Terms-of-trade analysis